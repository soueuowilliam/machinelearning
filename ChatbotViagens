Sr. Passeador: Chatbot de Viagens com Mem√≥ria (LangChain + Gemini)
Este reposit√≥rio cont√©m um assistente virtual conversacional especializado em turismo brasileiro. Diferente de bots comuns, o Sr. Passeador utiliza o gerenciamento de estado do LangChain para manter o contexto da conversa, permitindo que o usu√°rio fa√ßa perguntas de acompanhamento sem precisar repetir informa√ß√µes anteriores.

üåü Destaques
Persona Customizada: Atua como um guia especializado chamado "Sr. Passeador".
Gerenciamento de Sess√£o: Suporta m√∫ltiplas conversas independentes simult√¢neas atrav√©s de IDs de sess√£o.
Mem√≥ria Contextual: Implementa InMemoryChatMessageHistory para lembrar destinos e prefer√™ncias mencionadas durante o chat.
Integra√ß√£o com Gemini 2.5 Flash: Processamento de linguagem natural de √∫ltima gera√ß√£o para respostas r√°pidas e precisas.

üèóÔ∏è Arquitetura do Sistema
O fluxo de dados funciona atrav√©s do componente RunnableWithMessageHistory, que atua como um intermedi√°rio entre o usu√°rio e o modelo de IA:
Input: O usu√°rio envia uma pergunta.
Recupera√ß√£o: O sistema busca o hist√≥rico de mensagens associado ao session_id.
Aumenta√ß√£o: O hist√≥rico √© injetado no prompt atrav√©s do placeholder {historico}.
Gera√ß√£o: O modelo Gemini gera a resposta baseada na pergunta atual + contexto anterior.
Armazenamento: A nova intera√ß√£o √© salva na mem√≥ria para a pr√≥xima pergunta.

üõ†Ô∏è Tecnologias e Bibliotecas
LangChain Core & Google GenAI: Motor de orquestra√ß√£o e interface com a IA.
Pydantic: Para valida√ß√£o de esquemas de dados.
Python-dotenv: Seguran√ßa de chaves de API.
InMemoryChatMessageHistory: Armazenamento tempor√°rio de conversas em RAM.

============================================================================================================================================

#IMPORT LANGCHAIN
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langchain_core.chat_history import InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.globals import set_debug

#IMPORT SYSTEM
from pydantic import Field, BaseModel
from dotenv import load_dotenv
import os

load_dotenv()
key = os.getenv('GOOGLE_API_KEY')

modelo = ChatGoogleGenerativeAI(model = 'gemini-2.5-flash', temperature = 0.5, api_key = key)
sugestao = ChatPromptTemplate.from_messages([
    ('system', 'Voc√™ √© um guia de viagem especializado em destinos Brasileiros. Apresente-se como Sr. Passeador'),
    ('placeholder', '{historico}'),
    ('human', '{pergunta}')
])

memoria = {}
sessao = 'langchain'

def historico_sessao(sessao:str):
    if sessao not in memoria:
        memoria[sessao] = InMemoryChatMessageHistory()
    return memoria[sessao]


chain = sugestao | modelo | StrOutputParser()

cadeia_memoria = RunnableWithMessageHistory(
    runnable = chain,
    get_session_history = historico_sessao,
    input_messages_key = 'pergunta',
    history_messages_key = 'historico'
)

question = [
    'Quero visitar um lugar no Brasil, famoso por praias e culturas. Pode sugerir?',
    'Qual a melhor √©poca do ano para ir?'
]


for pergunta in question:
    resposta = cadeia_memoria.invoke({'pergunta': pergunta}, config = {'session_id': sessao})
    print(resposta)
